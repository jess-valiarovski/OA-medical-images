{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfc93ce",
   "metadata": {},
   "source": [
    "# Using Metadata to Improve Artifical Intelligance Medical Image Diagnostic Accuracy\n",
    "**Purpose and Background**\n",
    "Conduct a descriptive analysis of crowdsourced data extracted from user interaction with a mobile application where tasked to binarly (yes or no) identify abnormalities in medical images. \n",
    "\n",
    "Two user categories were differentiated: Medical experts hired to interact with the application; and crowd, anyone who downloaded and used the application.\n",
    "\n",
    "**Show that the crowd agrees with the expert majority more than experts agreeing with the expert majority**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132215a",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0bed0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "results = pd.read_csv('1345_customer_results.csv') #medical case results\n",
    "admin = pd.read_csv('1345_admin_reads.csv') #raw individual read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbe40d",
   "metadata": {},
   "source": [
    "### Inspect Customer Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae1b2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dtypes\n",
    "results = results.set_index('Case ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aafbf1b",
   "metadata": {},
   "source": [
    "**Preliminary filtering for security purposes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ab34a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.dropna(subset=['Origin']) \n",
    "results[\"Expert: Abnormal Votes\"] = results[\"Origin\"].str.extract(r'vote(\\d)').astype(float)\n",
    "results = results.drop(['Origin Created At','Origin','Content ID','URL'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a936ad61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3eec1",
   "metadata": {},
   "source": [
    "Any rows that did not have a string associated with expert votes in the URL were dropped (i.e. NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26e6821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.dropna(subset=[\"Expert: Abnormal Votes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b466c6",
   "metadata": {},
   "source": [
    "**Inspect NaN Columns for Content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c1070cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['Series'].notna()| results['Series Index'].notna() | results['Patch'].notna() | results['Internal Notes'].notna() | results['Explanation'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98257c2",
   "metadata": {},
   "source": [
    "Dataframe is empty; columns inspected will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dbfb9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop(['Series','Series Index','Patch','Internal Notes','Explanation'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff585e",
   "metadata": {},
   "source": [
    "**Inspect Comments for Relevance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c781961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results[results['Comments'] != '[]']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2301bad",
   "metadata": {},
   "source": [
    "None of the comments seem relevant; comments column will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b5b8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop(['Comments'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a57c48",
   "metadata": {},
   "source": [
    "There should only be 8 experts total; drop cases for expert count greater than 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "020b9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[results[\"Expert: Abnormal Votes\"] <= 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a63a8f",
   "metadata": {},
   "source": [
    "### Important columns for analysis; original metadata\n",
    "Each row corresponds to a medical case \n",
    "\n",
    "**Identifiers:** \n",
    "\n",
    "Case ID: unique identifier will serve as index\n",
    "\n",
    "Labeling State: identifies whether a expert consensus has been achieved (yes=Gold Standard, no= In Progress)\n",
    "\n",
    "URL: Extracted out expert vote count within the URL \n",
    "\n",
    "**Reads and Annotations**\n",
    "\n",
    "Qualified Reads: total crowd vote count\n",
    "\n",
    "Expert: Abnormal Votes: number of experts who thought the case was abnormal\n",
    "\n",
    "(note, the total of experts voting is always 8)\n",
    "\n",
    "Correct Label: overall expert consensus \n",
    "\n",
    "{yes=case is abnormal, no=case is normal, NaN=no consensus}\n",
    "\n",
    "Majority Label: overall crowd consensus on each case\n",
    "\n",
    "**Measures of Confidence**\n",
    "\n",
    "Difficulty: Qualified Reads *without the Correct Label* divided by total Qualified Reads.\n",
    "\n",
    "Agreement: Qualified Reads *with the Majority Label* divided by total Qualified Reads.\n",
    "\n",
    "Nth Choice Answer: crowd answer (First Choice is the Majority Label)\n",
    "        \n",
    "Nth Choice Votes: number of crowd votes per answer\n",
    "        \n",
    "Nth Choice Weight:\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89528626",
   "metadata": {},
   "source": [
    "### Add Relevant Columns and Optimize Dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324729b0",
   "metadata": {},
   "source": [
    "#### Cluster cases categorically based on difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f93b9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,0.2,0.4,0.6,0.8,1]\n",
    "labels=['very easy','easy','moderate','challenging','very challenging']\n",
    "results['Difficulty Category'] = pd.cut(results['Difficulty'],bins=bins,labels=labels,include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99027cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results\n",
    "index = df.index[df['Crowd Majority']==\"'no'\"].tolist()\n",
    "df['Crowd Agreement'][index] -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_count = 8\n",
    "df[\"Expert: Normal Votes\"] = (expert_count - results[\"Expert: Abnormal Votes\"])\n",
    "df[\"Expert Agreement\"] = df[\"Expert: Abnormal Votes\"]/expert_count\n",
    "df['Consensus'] = np.where(df['Expert Majority'] == df['Crowd Majority'],'yes','no')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a30b3",
   "metadata": {},
   "source": [
    "#### Expert: Normal Votes:\n",
    "I subtracted the number of total experts by the known number of experts who voted the case as abnormal\n",
    "\n",
    "#### Expert Agreement: \n",
    "I divided the number of experts who voted the case as abnormal by the total number of experts to get the porportion of experts who agree that the case is abnormal.\n",
    "\n",
    "#### Error Rate: \n",
    "I extracted the indexes for each category and calculated the \"error rate\" for the experts who did not vote for the expert majority\n",
    "\n",
    "#### Consensus:\n",
    "I indiciated cases where there was unanimity between experts and crowd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b394235",
   "metadata": {},
   "source": [
    "### I will rename some of the original columns for clarity\n",
    "\n",
    "   #### {Original column --> Renamed Column}\n",
    "    \n",
    "    Correct Label --> Expert Majority\n",
    "\n",
    "    Majority Label --> Crowd Majority\n",
    "\n",
    "    Difficulty --> Expert/Crowd Disagreement\n",
    "\n",
    "    Agreement --> Crowd Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Expert Majority\"] = results[\"Correct Label\"]\n",
    "df[\"Crowd Majority\"] = results[\"Majority Label\"]\n",
    "df[\"Expert/Crowd Disagreement\"] = results[\"Difficulty\"] \n",
    "df[\"Crowd Agreement\"] = results[\"Agreement\"] \n",
    "df = df.drop(columns= [\"Correct Label\",\"Majority Label\",\"Difficulty\",\"Agreement\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e345b88",
   "metadata": {},
   "source": [
    "#### Expert/Crowd Disagreement \n",
    "is the porportion of crowd disagreeing with expert consensus (i.e. difficulty)\n",
    "\n",
    "#### Crowd Agreement\n",
    "is the porportion of crowd agreeing with crowd consensus (i.e. agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea75cec",
   "metadata": {},
   "source": [
    "#### Error rate of experts\n",
    "I extracted the indexes for each category and calculated the \"error rate\" for the experts who did not vote for the expert majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_yes = df.index[df['Expert Majority'] == \"'yes'\"].tolist()\n",
    "\n",
    "EM_no = df.index[df['Expert Majority'] == \"'no'\"].tolist()\n",
    "\n",
    "df.loc[EM_yes,\"Error Rate\"]= df['Expert: Normal Votes'][EM_yes]/expert_count\n",
    "df.loc[EM_no,\"Error Rate\"]= df['Expert: Abnormal Votes'][EM_no]/expert_count\n",
    "#df.fillna('', inplace=True)\n",
    "beg_index = list(df.columns).index('Expert: Abnormal Votes') #9\n",
    "df.iloc[ : , 13:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results\n",
    "index = df.index[df['Crowd Majority']==\"'no'\"].tolist()\n",
    "df['Crowd Agreement'][index] -= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca45d6d9",
   "metadata": {},
   "source": [
    "## Exploratory Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install jupyter-dash\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.figure_factory as ff\n",
    "pio.renderers.default='notebook'\n",
    "import matplotlib.pyplot as plt\n",
    "#ax = plt.subplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIX NaN; currently is blank\n",
    "#df.fillna('', inplace=True)\n",
    "print(df['Expert Majority'].value_counts())\n",
    "#df[df[\"Expert Majority\"]].isnull()\n",
    "print(df['Expert Majority'].isnull().any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21c2fb",
   "metadata": {},
   "source": [
    "12,000 medical cases were judged to be abnormal by experts\n",
    "\n",
    "12,000 medical cases were judged to be normal by experts\n",
    "\n",
    "3,0000 medical cases failed to reach a consensus (4 experts voted for normal and 4 experts voted for abnormal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f4d09",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837bd1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a2715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4be15fb1",
   "metadata": {},
   "source": [
    "#### How reliable are the individual experts on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95f318",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27347876",
   "metadata": {},
   "source": [
    "With the number of experts being 8, filtering the qualified reads to 5 or more would keep things more porportional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df = df[df['Qualified Reads'] >= 5]\n",
    "fig = px.density_heatmap(filt_df, x=\"Expert Majority\", y='Crowd Majority',text_auto=True)\n",
    "fig.show()\n",
    "filt_df.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07b4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3133dc1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(df['Expert: Normal Votes']+df['Expert: Abnormal Votes'])-sum(df['Qualified Reads']))\n",
    "\n",
    "print(sum(filt_df['Expert: Normal Votes']+filt_df['Expert: Abnormal Votes'])-sum(filt_df['Qualified Reads']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5938a3c",
   "metadata": {},
   "source": [
    "#### When we filtered the qualified reads to 5 or more, the disparity between expert vote count and reader vote count across all cases significantly decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b46398b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#consensus_yes = filt_df.index[filt_df['Consensus']=='yes'].tolist()\n",
    "\n",
    "fig2 = px.histogram(filt_df, \n",
    "                    x='Expert Agreement',color='Expert Majority',\n",
    "                    marginal='violin',color_discrete_map={\"'yes'\":'purple',\"'no'\":'red'}, \n",
    "                    labels={'x' : 'Agreement Ratio', 'y' : 'Count'},\n",
    "                   )\n",
    "fig1 = px.histogram(filt_df, x='Crowd Agreement',color='Crowd Majority',marginal='violin', color_discrete_map={\"'yes'\":'green',\"'no'\":'yellow'})\n",
    "fig2.update_layout(title_text='Experts',\n",
    "    title_x=0.5, showlegend=True,\n",
    "    legend_title=None)\n",
    "fig1.data[0].name=\"Crowd Majority: Yes\"\n",
    "fig2.data[0].name=\"Expert Majority: No\"\n",
    "fig1.data[2].name=\"Crowd Majority: No\"\n",
    "fig2.data[2].name=\"Expert Majority: Yes\"\n",
    "fig2.add_trace(fig1.data[0])\n",
    "fig2.add_trace(fig1.data[1])\n",
    "fig2.add_trace(fig1.data[2])\n",
    "fig2.add_trace(fig1.data[3])\n",
    "\n",
    "split_conses = filt_df[filt_df[\"Expert Agreement\"]==0.5]\n",
    "fig3 = px.histogram(split_conses, x='Expert Agreement',color='Expert Majority', color_discrete_map={'nan':'blue'}) #won't change to blue\n",
    "fig3.data[0].name=\"Expert Majority: NaN\"\n",
    "fig2.add_trace(fig3.data[0])\n",
    "\n",
    "fig2.update_layout(barmode='overlay')\n",
    "fig2.update_xaxes(dtick=0.2)\n",
    "fig2.update_traces(opacity=0.32)\n",
    "import plotly.graph_objects as go\n",
    "fig2.add_shape(type=\"rect\",x0=0.493,x1=0.525,y0=0,y1=3000,line_width=1,line_dash='dot')\n",
    "#fig2.add_trace(go.Scatter(filt_df.loc[consensus_no], x)\n",
    "fig2.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#consensus_yes = filt_df.index[filt_df['Consensus']=='yes'].tolist()\n",
    "\n",
    "\n",
    "fig1 = px.histogram(filt_df, x='Crowd Agreement',color='Crowd Majority', color_discrete_map={\"'yes'\":'green',\"'no'\":'yellow'},\n",
    "                   text_auto=True)\n",
    "\n",
    "fig1.data[1].name=\"Crowd Majority: No\"\n",
    "\n",
    "\n",
    "fig1.data[0].name=\"Crowd Majority: Yes\"\n",
    "\n",
    "fig3 = px.histogram(split_conses, x='Expert Agreement',color='Expert Majority', color_discrete_map={'nan':'orange'},\n",
    "                   text_auto=True) #won't change color\n",
    "fig3.data[0].name=\"Expert Majority: NaN\"\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=1,cols=3)\n",
    "fig.add_trace(fig3.data[0],row=1,col=1)\n",
    "fig.update_xaxes(title_text='Expert Majority: NaN',row=1,col=1)\n",
    "\n",
    "fig.add_trace(fig1.data[1],row=1,col=2)\n",
    "fig.update_xaxes(title_text='Crowd Majority: No',row=1,col=2)\n",
    "fig.update_xaxes(range=[0.49,0.51])\n",
    "\n",
    "fig.add_trace(fig1.data[0],row=1,col=3)\n",
    "\n",
    "fig.add_annotation(text=\"393\",row=1,col=3)\n",
    "fig.update_xaxes(title_text='Crowd Majority: Yes',range=[0.49,0.61],row=1,col=3)\n",
    "\n",
    "\n",
    "fig.update_yaxes(range=[0,3000])\n",
    "fig.update_traces(opacity=0.6)\n",
    "fig.update_layout(title_text=\"Frequency of Split Agreement\")\n",
    "fig.add_shape(type=\"rect\",x0=0.493,x1=0.507,y0=0,y1=2950,line_width=1,line_dash='dot', row=1,col=1)\n",
    "fig.add_shape(type=\"rect\",x0=0.493,x1=0.507,y0=0,y1=2950,line_width=1,line_dash='dot', row=1,col=2)\n",
    "fig.add_shape(type=\"rect\",x0=0.502,x1=0.602,y0=0,y1=2950,line_width=1,line_dash='dot', row=1,col=3)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b378cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a527f7e",
   "metadata": {},
   "source": [
    "When the experts are undecided (N=4) on the case prognosis, crowd appears to have a more unified opinion on the case. Let's make a histogram examining the cases where there's lack of consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f00034",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53384782",
   "metadata": {},
   "source": [
    "## When crowd disagrees with experts, how divded are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec137788",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_no = filt_df.index[filt_df['Consensus']=='no'].tolist()\n",
    "\n",
    "fig2 = px.histogram(filt_df.loc[consensus_no], \n",
    "                    x='Expert Agreement',color='Expert Majority',\n",
    "                    marginal='violin',color_discrete_map={\"'yes'\":'purple',\"'no'\":'red'}, \n",
    "                    labels={'x' : 'Agreement Ratio', 'y' : 'Count'},\n",
    "                   )\n",
    "fig1 = px.histogram(filt_df.loc[consensus_no], x='Crowd Agreement',color='Crowd Majority',marginal='violin', color_discrete_map={\"'yes'\":'green',\"'no'\":'yellow'})\n",
    "fig2.update_layout(title_text='Experts',\n",
    "    title_x=0.5, showlegend=True,\n",
    "    legend_title=None)\n",
    "fig1.data[0].name=\"Crowd Majority: Yes\"\n",
    "fig2.data[0].name=\"Expert Majority: No\"\n",
    "fig1.data[2].name=\"Crowd Majority: No\"\n",
    "fig2.data[2].name=\"Expert Majority: Yes\"\n",
    "fig2.add_trace(fig1.data[0])\n",
    "fig2.add_trace(fig1.data[1])\n",
    "fig2.add_trace(fig1.data[2])\n",
    "fig2.add_trace(fig1.data[3])\n",
    "\n",
    "\n",
    "fig2.update_layout(barmode='overlay')\n",
    "fig2.update_xaxes(dtick=0.2)\n",
    "fig2.update_traces(opacity=0.32)\n",
    "import plotly.graph_objects as go\n",
    "fig2.add_shape(type=\"rect\",x0=0.5,x1=0.55,y0=0,y1=750,line_width=1,line_dash='dot')\n",
    "#fig2.add_trace(go.Scatter(filt_df.loc[consensus_no], x)\n",
    "fig2.show()\n",
    "fig2.update_layout(title_text='ALPACA Queries Left',\n",
    "    title_x=0.5, showlegend=True,\n",
    "    legend_title=None)\n",
    "fig2.show()\n",
    "fig2.update_xaxes(range=[0.55,1.1])\n",
    "fig2.update_layout(title_text='ALPACA Queries Right',\n",
    "    title_x=0.5, showlegend=True,\n",
    "    legend_title=None)\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5dd039",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb92b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1c28b6",
   "metadata": {},
   "source": [
    "## When experts can't decide case status, what does the crowd think?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1397c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.histogram(filt_df.loc[experts_split], x='Crowd Agreement',color='Crowd Majority',marginal='box')\n",
    "#fig.show()\n",
    "\n",
    "\n",
    "split_conses = filt_df.index[filt_df[\"Expert Agreement\"]==0.5].tolist()\n",
    "fig3 = px.histogram(filt_df[split_conses], x='Crowd Agreement',color='Crowd Majority')\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b986e1f",
   "metadata": {},
   "source": [
    "Seems uniform; which cases fall into the category? Are they the harder ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0e4a5",
   "metadata": {},
   "source": [
    "Make these into bubble charts to show porportion: https://plotly.com/python/bubble-charts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0100fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab71985b",
   "metadata": {},
   "source": [
    "### Problem x User Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52097783",
   "metadata": {},
   "source": [
    "#### Isolate Problem_id, User_id, accuracy, chosen answer, and correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin = pd.read_csv('1345_admin_reads.csv') #raw individual read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504037ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin\n",
    "#results = results.set_index('Case ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "PU_df = admin\n",
    "PU_df = PU_df.set_index('read_id')\n",
    "PU_df = admin[['problem_id','user_id','accuracy','chosen_answer']].copy()\n",
    "PU_df = pd.concat([filt_df[['Expert Majority']],PU_df],axis=1)\n",
    "PU_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "PU_matrix_accur = PU_df.pivot_table(index='problem_id',columns='user_id',values='accuracy', aggfunc='mean')\n",
    "PU_matrix_accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_accuracy_table = pd.DataFrame(PU_matrix_accur.mean())\n",
    "user_accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5414a7",
   "metadata": {},
   "source": [
    "Average accuracy of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b00855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PU_matrix_corr = PU_df.pivot_table(index='problem_id',columns='user_id',values='Expert Majority', aggfunc='sum')\n",
    "#PU_matrix_corr\n",
    "PU_matrix_accur.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962d2ab",
   "metadata": {},
   "source": [
    "### SciKit/Weighted Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deslib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc821b",
   "metadata": {},
   "source": [
    "META-DES 7, 8, 15\n",
    ": R. M. O. Cruz, R. Sabourin, G. D. C. Cavalcanti, T. I. Ren, META-DES: A dynamic ensemble selection framework using meta-learning, Pattern Recognition 48 (5) (2015) 1925–1935.\n",
    "\n",
    "Cruz, R.M., Sabourin, R. and Cavalcanti, G.D., 2015, July. META-DES. H: a dynamic ensemble selection technique using meta-learning and a dynamic weighting approach. In Neural Networks (IJCNN), 2015 International Joint Conference on (pp. 1-8)\n",
    "\n",
    "R. M. O. Cruz, R. Sabourin, G. D. C. Cavalcanti, META-DES.Oracle: Meta-learning and feature selection for dynamic ensemble selection, Information Fusion 38 (2017) 84–103.Nov 30;38:84-103.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971244f1",
   "metadata": {},
   "source": [
    " This method (Dynamic Ensemble Selection-Kullback-Leibler divergence (DES-KL).) estimates the competence of the classifier (the ability of the user to answer correctly) and puts them into clusters categorizing groups that answer more accurately than others.\n",
    "\n",
    "https://github.com/scikit-learn-contrib/DESlib/blob/master/deslib/des/probabilistic/deskl.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from deslib.des.probabilistic import BaseProbabilistic\n",
    "from deslib.util import entropy_func\n",
    "\n",
    "\n",
    "class DESKL(BaseProbabilistic):\n",
    "    \n",
    "    def __init__(self, pool_classifiers=None, k=None, DFP=False, with_IH=False,\n",
    "                 safe_k=None, IH_rate=0.30, mode='selection',\n",
    "                 random_state=None, knn_classifier='knn',\n",
    "                 knn_metric='minkowski', DSEL_perc=0.5, n_jobs=-1,\n",
    "                 voting='hard'):\n",
    "        super(DESKL, self).__init__(pool_classifiers=pool_classifiers,\n",
    "                                    k=k,\n",
    "                                    DFP=DFP,\n",
    "                                    with_IH=with_IH,\n",
    "                                    safe_k=safe_k,\n",
    "                                    IH_rate=IH_rate,\n",
    "                                    mode=mode,\n",
    "                                    random_state=random_state,\n",
    "                                    knn_classifier=knn_classifier,\n",
    "                                    knn_metric=knn_metric,\n",
    "                                    DSEL_perc=DSEL_perc,\n",
    "                                    n_jobs=n_jobs,\n",
    "                                    voting=voting)\n",
    "\n",
    "        self.selection_threshold = 0.0\n",
    "\n",
    "    def source_competence(self):\n",
    "        \"\"\"Calculates the source of competence using the KL divergence method.\n",
    "\n",
    "        The source of competence C_src at the validation point\n",
    "        :math:`\\\\mathbf{x}_{k}` is calculated by the KL divergence\n",
    "        between the vector of class supports produced by the base classifier\n",
    "        and the outputs of a random classifier (RC) RC = 1/L, L being the\n",
    "        number of classes in the problem. The value of C_src is negative if\n",
    "        the base classifier misclassified the instance :math:`\\\\mathbf{x}_{k}`.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        C_src : array of shape (n_samples, n_classifiers)\n",
    "            The competence source for each base classifier at each data point.\n",
    "        \"\"\"\n",
    "\n",
    "        C_src = np.zeros((self.n_samples_, self.n_classifiers_))\n",
    "        for clf_index in range(self.n_classifiers_):\n",
    "            supports = self.dsel_scores_[:, clf_index, :]\n",
    "            is_correct = self.DSEL_processed_[:, clf_index]\n",
    "            C_src[:, clf_index] = entropy_func(self.n_classes_, supports,\n",
    "                                               is_correct)\n",
    "\n",
    "        return C_src\n",
    "    \n",
    "DESKL(PU_matrix_accur.keys(),k=10, knn_metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7fc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
